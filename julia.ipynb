{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalação e importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_community faiss-cpu langchain_openai langchain_text_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialização do cliente OpenAI para transcrição de áudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "audio_file = open(\"audio.mp3\", \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file\n",
    ")\n",
    "print(transcription.text)  # Exibição da transcrição do áudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialização do modelo de linguagem GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento e divisão do documento de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file_path = \"./rag-voicebot.txt\"\n",
    "loader = TextLoader(file_path=txt_file_path, encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=100)\n",
    "data = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação de embeddings usando a OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(api_key=api_key)\n",
    "vectorstore = FAISS.from_documents(data, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração do prompt para reformular perguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"\n",
    "Atue com a personalidade de um assistente profissional especializado em tarefas de\n",
    "resposta a perguntas relacionadas a serviços hospitalares.\n",
    "Dada a história do chat e a última pergunta do usuário, que pode referenciar o\n",
    "contexto na história do chat, reformule a pergunta de forma que possa ser entendida\n",
    "sem a necessidade da história do chat. NÃO responda à pergunta, apenas reformule-a\n",
    "se necessário e, caso contrário, retorne-a como está.\n",
    "O estilo de escrita é formal e claro, dirigido a pacientes e visitantes do hospital.\n",
    "Você deve ficar atento ao histórico do chat para determinar se uma consulta já foi marcada,\n",
    "ou seja, se alguém marcou consulta antes da pessoa, você deve retornar que está indisponível.\n",
    "\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação de um retriever consciente do histórico do chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração do prompt para responder a perguntas sobre serviços hospitalares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Atue com a personalidade de um assistente profissional especializado em tarefas de resposta a perguntas relacionadas a serviços hospitalares.\n",
    "\n",
    "Responda a consultas relacionadas ao Hospital BIAmigos, direcionando para dois possíveis ramos: informações sobre o hospital ou agendamento de consultas médicas.\n",
    "Caso seja sobre agendamento de consultas médicas, confira imediatamente se a pessoa adicionou o nome, CPF e telefone. Se adicionou continue normalmente, caso não\n",
    "exija imediatamente o preenchimento dessas informações.\n",
    "Você deve ficar atento ao histórico do chat para determinar se uma consulta já foi marcada,\n",
    "ou seja, se alguém marcou consulta antes da pessoa, você deve retornar que está indisponível.\n",
    "O estilo de escrita é formal e claro, dirigido a pacientes e visitantes do hospital.\n",
    "Sempre tente trazer as pessoas para o BIAmigos Hospital, ou seja, convide-as quando precisarem de ajuda para vir ao hospital.\n",
    "\n",
    "Você deve considerar o seguinte contexto:\n",
    "\n",
    "- O hospital é BIAmigos Hospital.\n",
    "- Os departamentos são: Cardiologia, Pediatria, Ortopedia, Dermatologia e Neurologia.\n",
    "- Conhecimento de: horários de atendimento, nomes dos doutores e departamentos, além de um roteiro de instruções para pronto socorro.\n",
    "- Sem horário estabelecido para marcação de consultas, mas com conhecimento sobre a disponibilidade dos médicos.\n",
    "- Procedimento para marcação de consultas: Nome, CPF e Telefone.\n",
    "- Redirecionar para atendente humano em caso de dúvida específica, como uso de medicamentos.\n",
    "- Canal de comunicação: Telefone.\n",
    "\\n\\n\n",
    "{context}\n",
    "\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação de uma cadeia de perguntas e respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histórico de mensagens do chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação da cadeia conversacional RAG com histórico de mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste da cadeia conversacional com uma mensagem de exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Oi, meu nome é Júlia. Queria marcar uma consulta com a Doutora Ana Souza às 09:00 horas da segunda-feira, ela tem disponibilidade?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exibição das mensagens no histórico do chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "for message in store[\"abc123\"].messages:\n",
    "    if isinstance(message, AIMessage):\n",
    "        prefix = \"AI\"\n",
    "    else:\n",
    "        prefix = \"User\"\n",
    "    print(f\"{prefix}: {message.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilização da resposta para gerar um arquivo de áudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = f\"{answer}\"\n",
    "model = \"tts-1\"\n",
    "voice = \"shimmer\"\n",
    "response = client.audio.speech.create(model=model, voice=voice, input=text_input)\n",
    "response.write_to_file(\"output.mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
